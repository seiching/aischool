{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "FaceNet_organize.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seiching/aischool/blob/master/FaceNet_organize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mlg6GrxTpdLm",
        "colab_type": "text"
      },
      "source": [
        "#### 參考資料:\n",
        "1. https://machinelearningmastery.com/how-to-develop-a-face-recognition-system-using-facenet-in-keras-and-an-svm-classifier/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVWpQ6XV9Uwd",
        "colab_type": "text"
      },
      "source": [
        "## 連結google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmMxmzyCpzIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQrW8eFZ9d9f",
        "colab_type": "text"
      },
      "source": [
        "## 解壓縮資料tar(如果資料損毀)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwa8AzHVyHj9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls\n",
        "%cd '/content/drive/My Drive/FaceNet_Colab'\n",
        "!ls\n",
        "#!tar -xvf aia-tpe4-who-is-she.tar \n",
        "print('\\nunzip over')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaMzzM_r_0n5",
        "colab_type": "text"
      },
      "source": [
        "### 1.開始計時"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjuASgKc_upf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "print(\"hello...%d\"%start)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFsr_3oypdLn",
        "colab_type": "text"
      },
      "source": [
        "# 初始化模型建置:\n",
        "首先，Import everythings to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSOSB4Qp91Ja",
        "colab_type": "text"
      },
      "source": [
        "### 1.安裝MTCNN模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIfh4lSm1rHF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install mtcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8DlSjDa-G9O",
        "colab_type": "text"
      },
      "source": [
        "### 2.導入相關module\n",
        "module指的是相關的程序檔案，可能是整份文件，也可能是其中的某幾個類別(class)。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jBxHfm6pdLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# face detection for the 5 Celebrity Faces Dataset\n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "# develop a classifier for the 5 Celebrity Faces Dataset\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "import csv\n",
        "import pandas as pd\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snd_Fn4PpdLs",
        "colab_type": "text"
      },
      "source": [
        "### 3.定義相關function:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiVeTik3AJoY",
        "colab_type": "text"
      },
      "source": [
        "#### extract_face\n",
        "導入MTCNN()進行人臉識別。<br>\n",
        "利用PIL module操作影像，並使用MTCNN模型進行辨識，並從中產出影像中包含的人臉影像，重新裁剪成一張160x160的影像。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tKWCXRypdLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# extract a single face from a given photograph\n",
        "\n",
        "# from PIL import Image\n",
        "def extract_face(filename,  required_size=(160,  160)):\n",
        "    # load image from file\n",
        "    image  =  Image.open(filename)\n",
        "    # convert to RGB, if needed\n",
        "    image  =  image.convert('RGB')\n",
        "    # convert to array\n",
        "    pixels  =  asarray(image)\n",
        "    # create the detector, using default weights\n",
        "    detector  =  MTCNN()\n",
        "    # detect faces in the image\n",
        "    results  =  detector.detect_faces(pixels)\n",
        "    # extract the bounding box from the first face\n",
        "    x1,  y1,  width,  height  = results[0]['box']\n",
        "    # bug fix\n",
        "    x1,  y1  =  abs(x1),  abs(y1)\n",
        "    x2,  y2  =  x1  +  width,  y1  +  height\n",
        "    # extract the face\n",
        "    face  =  pixels[y1:y2,  x1:x2]\n",
        "    # resize pixels to the model size\n",
        "    image  =  Image.fromarray(face)\n",
        "    image  =  image.resize(required_size)\n",
        "    face_array  =  asarray(image)\n",
        "    return  face_array\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fU65XNBkA27R",
        "colab_type": "text"
      },
      "source": [
        "#### load_faces10\n",
        "應用extract_face從指定資料夾中，產出所有影像中包含的人臉影像。並產出所有檔案的列表，以及無法被處理人臉識別的影像列表。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsgPWIMTpdLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load images and extract faces for all images in a directory\n",
        "\n",
        "def load_faces10(directory):\n",
        "    except_file = list()\n",
        "    files = list()\n",
        "    faces  =  list()\n",
        "    # enumerate files\n",
        "    for  filename in  listdir(directory):\n",
        "        # path\n",
        "        print(filename)\n",
        "        if filename == '.ipynb_checkpoints':\n",
        "            continue\n",
        "        if filename == '.csv':\n",
        "            continue\n",
        "        path  =  directory  +  filename\n",
        "        print(path)\n",
        "        filename = filename[:-4]\n",
        "        # get face\n",
        "        try:\n",
        "            face  =  extract_face(path)\n",
        "            # store\n",
        "            faces.append(face)\n",
        "            files.append(filename)\n",
        "        except(IndexError,IsADirectoryError,OSError):\n",
        "            except_file.append(filename)\n",
        "            print('except file...'+str(filename))\n",
        "            pass\n",
        "\n",
        "    return  faces, files, except_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njmoOHBzDgyF",
        "colab_type": "text"
      },
      "source": [
        "#### load_dataset10\n",
        "從指定資料夾中條列其子資料夾，並對每一個資料夾應用load_face10。最後會取得資料夾內所有類別的影像中包含的人臉影像，也會產出所有檔案的列表，以及無法被處理人臉嵌入的影像列表。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Tj-db9pdLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load a dataset that contains one subdir for each class that in turn contains images\n",
        "\n",
        "def load_dataset10(directory):\n",
        "    X,  y  =  list(),  list()\n",
        "    # enumerate folders, on per class\n",
        "    list_file = []\n",
        "    list_except_file = []\n",
        "    for  subdir in  listdir(directory):\n",
        "        # path\n",
        "        if subdir == '.ipynb_checkpoints':\n",
        "            continue\n",
        "\n",
        "        path  =  directory  +  subdir  +  '/'\n",
        "        # skip any files that might be in the dir\n",
        "        if  not  isdir(path):\n",
        "            continue\n",
        "        # load all faces in the subdirectory\n",
        "        faces, files, list_except_file =  load_faces10(path) # 改成修訂版\n",
        "        list_file.append(files)\n",
        "        # create labels\n",
        "        labels  =  [subdir for  _  in  range(len(faces))]\n",
        "        # summarize progress\n",
        "        print('>loaded %d examples for class: %s'  %  (len(faces),  subdir))\n",
        "        # store\n",
        "        X.extend(faces)\n",
        "        y.extend(labels)\n",
        "        \n",
        "    return  asarray(X),  asarray(y), list_file, list_except_file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9libm188G57M",
        "colab_type": "text"
      },
      "source": [
        "#### load_dataset\n",
        "從指定資料夾中條列其子資料夾，並對每一個資料夾應用load_face10。最後會取得資料夾內所有類別影像的人臉影像。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t_oO3oQpdL1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load a dataset that contains one subdir for each class that in turn contains images\n",
        "def load_dataset(directory, num):\n",
        "    X,  y  =  list(),  list()\n",
        "    # enumerate folders, on per class\n",
        "    for  subdir in  listdir(directory):\n",
        "        #print(subdir)\n",
        "        # path\n",
        "        if subdir == '.ipynb_checkpoints':\n",
        "            continue\n",
        "        path  =  directory  +  subdir  +  '/'\n",
        "        # skip any files that might be in the dir\n",
        "        if  not  isdir(path):\n",
        "            continue\n",
        "        # load all faces in the subdirectory\n",
        "        faces  =  load_faces(path, num)\n",
        "        # create labels\n",
        "        labels  =  [subdir for  _  in  range(len(faces))]\n",
        "        # summarize progress\n",
        "        print('>loaded %d examples for class: %s'  %  (len(faces),  subdir))\n",
        "        # store\n",
        "        X.extend(faces)\n",
        "        y.extend(labels)\n",
        "    return  asarray(X),  asarray(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCREyTb1HEMN",
        "colab_type": "text"
      },
      "source": [
        "#### load_faces\n",
        "應用extract_face從指定資料夾中，產出所有影像中包含的人臉影像。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w4SEBRnpdL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load images and extract faces for all images in a directory\n",
        "def load_faces(directory, num):\n",
        "    faces  =  list()\n",
        "    # enumerate files\n",
        "    \n",
        "    for  filename in  listdir(directory):\n",
        "        # path\n",
        "        if filename == '.ipynb_checkpoints':\n",
        "            continue\n",
        "        path  =  directory  +  filename\n",
        "        \n",
        "        # get face\n",
        "        try:\n",
        "            if num is None:\n",
        "                continue\n",
        "            else:\n",
        "                num = num-1\n",
        "                if num<0:\n",
        "                    break\n",
        "            print(path)\n",
        "            face  =  extract_face(path)\n",
        "            # store\n",
        "            faces.append(face)\n",
        "        except(IndexError,IsADirectoryError,OSError):\n",
        "            print('^^^-this file is error')\n",
        "            num=num+1\n",
        "            pass\n",
        "    return  faces"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wiuyq_KrHJIJ",
        "colab_type": "text"
      },
      "source": [
        "#### list_dul\n",
        "將list重新排列成 nxrow/ 1xcolumn 的list。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRq6cYqDpdL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get all the strings in another list. Also reorganization it to a n*row/1*column array. \n",
        "\n",
        "def list_dul(lista):\n",
        "    listb = []\n",
        "    for i in range(len(lista)): # how many folders(classes) in original folder.\n",
        "        for j in range(len(lista[i])): # how many images in each folder(class).\n",
        "            a = lista[i][j]\n",
        "            listb.append(a)\n",
        "    return listb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh3B3dkcLJHQ",
        "colab_type": "text"
      },
      "source": [
        "#### get_embedding\n",
        "從單一人臉影像中取得人臉嵌入(Face Embedding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCDhddCdLIBi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the face embedding for one face\n",
        "def get_embedding(model,  face_pixels):\n",
        "    # scale pixel values\n",
        "    face_pixels  =  face_pixels.astype('float32')\n",
        "    # standardize pixel values across channels (global)\n",
        "    mean,  std  =  face_pixels.mean(),  face_pixels.std()\n",
        "    face_pixels  =  (face_pixels  -  mean)  /  std\n",
        "    # transform face into one sample\n",
        "    samples  =  expand_dims(face_pixels,  axis=0)\n",
        "    # make prediction to get embedding\n",
        "    yhat  =  model.predict(samples)\n",
        "    #print(yhat[0])\n",
        "    return  yhat[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1oxr3ACpdL9",
        "colab_type": "text"
      },
      "source": [
        "# 輸入影像並產生人臉嵌入(Face Embedding)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guZxpYW8H5kz",
        "colab_type": "text"
      },
      "source": [
        "### 1.設定資料夾路徑"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY4vMED017hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('training_set')\n",
        "\n",
        "\n",
        "\n",
        "!ls '/content/drive/My Drive/FaceNet_Colab/aia-tpe4-who-is-she/training_set/'\n",
        "dir_training_data = '/content/drive/My Drive/FaceNet_Colab/aia-tpe4-who-is-she/training_set/'\n",
        "\n",
        "print('testing_set')\n",
        "!ls '/content/drive/My Drive/FaceNet_Colab/aia-tpe4-who-is-she/valid/'\n",
        "#testing_data = '/content/drive/My Drive/FaceNet_Colab/aia-tpe4-who-is-she/testing_set/' #testing data\n",
        "dir_testing_data = '/content/drive/My Drive/FaceNet_Colab/aia-tpe4-who-is-she/valid/' #validation data\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LG50Ew0THenq",
        "colab_type": "text"
      },
      "source": [
        "### 2.設定變數名稱\n",
        "其中包含兩個在過程中會產出的資料壓縮檔，分別是:\n",
        "1. 來源資料的資料壓縮檔\n",
        "2. 人臉嵌入壓縮檔(包括訓練與測試資料)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnvEcp8ipdL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting name \n",
        "new_dataset = 'girls_dataset30.npz'\n",
        "new_embeddings= 'girls_embeddings30.npz'\n",
        "# 20 for dul\n",
        "# 30 for ori\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azc0ThbUI3bA",
        "colab_type": "text"
      },
      "source": [
        "### 3.應用 load_dataset 從指定資料夾中導入訓練資料\n",
        "可以指定訓練資料個數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrGn8K-7pdMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load train dataset \n",
        "\n",
        "print('start to load and extract face image in training set')\n",
        "#trainX,  trainy  =  load_dataset('aia-tpe4-who-is-she/training_set')\n",
        "trainX,  trainy  =  load_dataset(dir_training_data,6)\n",
        "print(trainX.shape,  trainy.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fRABw2vJEiv",
        "colab_type": "text"
      },
      "source": [
        "### 4.應用 load_dataset10 從指定資料夾導入測試(驗證)資料\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGQcky4lpdMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load test dataset \n",
        "print('start to load and extractface image in testing set')\n",
        "testX,  testy, list_file, list_except_file =  load_dataset10(dir_testing_data)\n",
        "list_file = list_dul(list_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5bBkKrLJ9jx",
        "colab_type": "text"
      },
      "source": [
        "### 5.將訓練資料與測試資料壓縮成一個人臉資料封包\n",
        "人臉資料封包(new_dataset)中所有影像都只有人臉部分。<br>此過程同時也將無法被處理人臉嵌入的檔案存成一個panda array，留在記憶體中備用。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbzwon10wT_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save except file as a panda array\n",
        "list_except_file = pd.DataFrame(list_except_file)\n",
        "print('有 %d 個無法處理人臉嵌入的影像'%len(list_except_file))\n",
        "\n",
        "# print text data list\n",
        "print('list_file len:' + str(len (list_file)))\n",
        "print(testX.shape,  testy.shape)\n",
        "\n",
        "# save arrays to one file in compressed format  \n",
        "savez_compressed(new_dataset,  trainX,  trainy,  testX,  testy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fr3fFZjkKZGe",
        "colab_type": "text"
      },
      "source": [
        "### 6.導入人臉資料封包以及FaceNet模型\n",
        "facenet_keras.h5需要放在正確位置。可以透過 !ls 來確認所在位置是否包含該檔案。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kWF3YABYKtlD",
        "colab": {}
      },
      "source": [
        "#data  =  load('girls_dataset20.npz')\n",
        "data  =  load(new_dataset)\n",
        "\n",
        "trainX,  trainy,  testX,  testy  =  data['arr_0'],  data['arr_1'],  data['arr_2'],  data['arr_3']\n",
        "print('Loaded: ',  trainX.shape,  trainy.shape,  testX.shape,  testy.shape)\n",
        "print(type(trainX))\n",
        "# load the facenet model\n",
        "!ls \n",
        "model  =  load_model('facenet_keras.h5')\n",
        "print('Loaded Model')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJtOahnzNeiX",
        "colab_type": "text"
      },
      "source": [
        "### 7.應用get_embedding取得所有資料的人臉嵌入(Face Embedding)\n",
        "最後會壓縮成一個包含所有人臉嵌入資料的檔案new_embeddings。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5n4_UD2pdMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert each face in the train set to an embedding\n",
        "newTrainX  =  list()\n",
        "for  face_pixels in  trainX:\n",
        "    embedding  =  get_embedding(model,  face_pixels)\n",
        "    newTrainX.append(embedding)\n",
        "newTrainX  =  asarray(newTrainX)\n",
        "print(newTrainX.shape)\n",
        "# convert each face in the test set to an embedding\n",
        "newTestX  =  list()\n",
        "for  face_pixels in  testX:\n",
        "    embedding  =  get_embedding(model,  face_pixels)\n",
        "    newTestX.append(embedding)\n",
        "newTestX  =  asarray(newTestX)\n",
        "print(newTestX.shape)\n",
        "# save arrays to one file in compressed format \n",
        "\n",
        "#savez_compressed('girls_embeddings20.npz',  newTrainX,  trainy,  newTestX,  testy)\n",
        "savez_compressed(new_embeddings,  newTrainX,  trainy,  newTestX,  testy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKZcNTpi-N1k",
        "colab_type": "text"
      },
      "source": [
        "# 進行模型訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYaXpGHfOnQ6",
        "colab_type": "text"
      },
      "source": [
        "## 1.使用keras內建的SVC模型進行訓練\n",
        "投入FaceNet產生的人臉嵌入進行訓練。此過程中使用LabelEncoder來將字串形式的類別以數值編排。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qz1LiYlJpdMS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# develop a classifier for Dataset\n",
        "from random import choice\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from matplotlib import pyplot\n",
        "import csv\n",
        "# load faces\n",
        "#data  =  load('girls_dataset10.npz')\n",
        "# Load new faces J:\n",
        "\n",
        "#data  =  load('girls_dataset10.npz')\n",
        "data  =  load(new_dataset)\n",
        "\n",
        "testX_faces  =  data['arr_2']\n",
        "print('待測試資料整體的型態:')\n",
        "print(data['arr_2'].shape)\n",
        "print('待測試資料個體的型態:')\n",
        "print(data['arr_2'][0].shape)\n",
        "\n",
        "# load face embeddings\n",
        "#data  =  load('girls_embeddings10.npz')\n",
        "data  =  load(new_embeddings)\n",
        "\n",
        "trainX,  trainy,  testX,  testy  =  data['arr_0'],  data['arr_1'],  data['arr_2'],  data['arr_3']\n",
        "# normalize input vectors\n",
        "in_encoder  =  Normalizer(norm='l2')\n",
        "trainX  =  in_encoder.transform(trainX)\n",
        "testX  =  in_encoder.transform(testX)\n",
        "# label encode targets\n",
        "out_encoder  =  LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy  =  out_encoder.transform(trainy)\n",
        "testy  =  out_encoder.transform(testy)\n",
        "# fit model\n",
        "model  =  SVC(kernel='linear',  probability=True)\n",
        "model.fit(trainX,  trainy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo79MgrjRDUI",
        "colab_type": "text"
      },
      "source": [
        "## 2.完成訓練"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiYW9V-_7o7A",
        "colab_type": "text"
      },
      "source": [
        "## 3.停止計時"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIy4ZM1A7kN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "endTraining = time.time()\n",
        "print(endTraining - start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91vb8JnFpdMU",
        "colab_type": "text"
      },
      "source": [
        "# 進行預測"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwvic2Lx-sds",
        "colab_type": "text"
      },
      "source": [
        "## 1.對所有資料進行預測，產出預測列表並打印出圖片"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ess18FB1pdMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
        "#for selection in range(len(testX_faces)):\n",
        "78\n",
        "listc = []\n",
        "for  i  in  range(testX.shape[0]):\n",
        "    selection = i\n",
        "            # test model on a random example from the test dataset\n",
        "    #selection  =  choice([i  for  i  in  range(testX.shape[0])])\n",
        "    #selection = 1 #\n",
        "    random_face_pixels  =  testX_faces[selection] #資料的圓形\n",
        "    random_face_emb  =  testX[selection] #資料的臉\n",
        "    random_face_class  =  testy[selection]\n",
        "    random_face_name  =  out_encoder.inverse_transform([random_face_class])\n",
        "    # prediction for the face\n",
        "    samples  =  expand_dims(random_face_emb,  axis=0)\n",
        "    yhat_class  =  model.predict(samples)\n",
        "    yhat_prob  =  model.predict_proba(samples)\n",
        "    # get name\n",
        "    class_index  =  yhat_class[0]\n",
        "    class_probability  =  yhat_prob[0,class_index]  *  100\n",
        "    predict_names  =  out_encoder.inverse_transform(yhat_class)\n",
        "    print('Predicted: %s (%.3f)'  %  (predict_names[0],  class_probability))\n",
        "    print('Expected: %s'  %  random_face_name[0])\n",
        "    \n",
        "    #產生預測資料列表\n",
        "    listc.append(predict_names[0])\n",
        "    \n",
        "    pyplot.imshow(random_face_pixels)\n",
        "    title  =  '%s (%.3f)'  %  (predict_names[0],  class_probability)\n",
        "    pyplot.title(title)\n",
        "    pyplot.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luGXj3hrR4kQ",
        "colab_type": "text"
      },
      "source": [
        "## 2.將前一步驟的預測列表整理成指定的格式\n",
        "1.合併影像名稱與預測類別 <br>\n",
        "2.處理例外資料(隨機補值) <br>\n",
        "3.合併預測資料與例外資料 <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBelJ2dxpdMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n合併影像名稱與預測類別')\n",
        "print(len(listc))\n",
        "df = pd.DataFrame(list_file)\n",
        "df2 = pd.DataFrame(listc)\n",
        "df =pd.concat([df,df2], axis = 1)\n",
        "print(df.head())\n",
        "#df.to_csv('result1.csv',index=False )\n",
        "\n",
        "print('\\n處理例外資料(隨機補值)')\n",
        "except_list = []\n",
        "for _ in range(len(list_except_file)):\n",
        "    selection  =  choice([i  for  i  in  range(trainX.shape[0])])\n",
        "    random_class  =  trainy[selection]\n",
        "    random_class  =  out_encoder.inverse_transform([random_class])\n",
        "    except_list.append(random_class[0])\n",
        "df_except = pd.DataFrame(list_except_file)\n",
        "df_except_class = pd.DataFrame(except_list)\n",
        "df_except = pd.concat([df_except, df_except_class], axis = 1)\n",
        "print('[%d]'%len(df_except))\n",
        "print(df_except)\n",
        "\n",
        "print('\\n合併預測資料與例外資料')\n",
        "df = pd.concat([df,df_except], axis = 0)\n",
        "print(df)\n",
        "#df.to_csv('result1.csv',index=False )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHBZATJYSbCf",
        "colab_type": "text"
      },
      "source": [
        "# 輸出預測結果"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-t12AG7_w6S",
        "colab_type": "text"
      },
      "source": [
        "## 1.依據classmap將預測類別的字串進行轉換"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAuLBa3uzGHT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#原始資料\n",
        "print('原始預測列表')\n",
        "print(df.head(3))\n",
        "\n",
        "\n",
        "#讀取SampleSubmission，尋找指定的Column name\n",
        "print('根據指定的格式更改Column name')\n",
        "dfSampleSubmission = pd.read_csv('/content/drive/My Drive/FaceNet_Colab/aia-tpe4-who-is-she/sample_submission.csv')\n",
        "a = dfSampleSubmission.columns[0]\n",
        "b = dfSampleSubmission.columns[1]\n",
        "#更改Column name為指定的樣式\n",
        "df.columns=[a, b]\n",
        "print(df.head(3))\n",
        "print('-----------')\n",
        "\n",
        "#讀取ClassMap\n",
        "print('依據Classmap做classnum的數值化轉換')\n",
        "dfClassMap = pd.read_csv('/content/drive/My Drive/FaceNet_Colab/aia-tpe4-who-is-she/classmap.csv')\n",
        "#用for迴圈把原始資料的class依據ClassMap做數值轉換\n",
        "for _ in range(len(dfClassMap)):\n",
        "  a = str(dfClassMap.loc[_]['classname'])\n",
        "  b = str(dfClassMap.loc[_]['classnum'])\n",
        "  df['class'] = df['class'].str.replace(a,b)\n",
        "  \n",
        "#顯示修改後的資料\n",
        "print(df.head(3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeMqZ7Lu_nFE",
        "colab_type": "text"
      },
      "source": [
        "## 2.打印結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CO_mTMplpdMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "df.to_csv('result.csv',index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J20LCDd7sBf",
        "colab_type": "text"
      },
      "source": [
        "## 3.結束計時"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_B96X6CpdMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkZvn7KX4IwM",
        "colab_type": "text"
      },
      "source": [
        "# 計算正確率(Validation專用)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6s0mcNFXpdMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# develop a classifier for the 5 Celebrity Faces Dataset\n",
        "from numpy import load\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "# load dataset\n",
        "\n",
        "#data  =  load('girls_embeddings20.npz')\n",
        "data  =  load(new_embeddings)\n",
        "\n",
        "trainX,  trainy,  testX,  testy  =  data['arr_0'],  data['arr_1'],  data['arr_2'],  data['arr_3']\n",
        "print('Dataset: train=%d, test=%d'  %  (trainX.shape[0],  testX.shape[0]))\n",
        "# normalize input vectors\n",
        "in_encoder  =  Normalizer(norm='l2')\n",
        "trainX  =  in_encoder.transform(trainX)\n",
        "testX  =  in_encoder.transform(testX)\n",
        "# label encode targets\n",
        "out_encoder  =  LabelEncoder()\n",
        "out_encoder.fit(trainy)\n",
        "trainy  =  out_encoder.transform(trainy)\n",
        "testy  =  out_encoder.transform(testy)\n",
        "# fit model\n",
        "model  =  SVC(kernel='linear',  probability=True)\n",
        "model.fit(trainX,  trainy)\n",
        "# predict\n",
        "yhat_train  =  model.predict(trainX)\n",
        "yhat_test  =  model.predict(testX)\n",
        "# score\n",
        "score_train  =  accuracy_score(trainy,  yhat_train)\n",
        "score_test  =  accuracy_score(testy,  yhat_test)\n",
        "# summarize\n",
        "#print('Accuracy: train=%.3f, test=%.3f'  %  (score_train*100,  score_test*100))\n",
        "print('Accuracy:%.3f  '%(score_test*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2OhQ-AgpdMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}